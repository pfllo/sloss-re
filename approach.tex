\section{Our Approach}
%Briefly introduce the whole framework, and refer to each subsection one by one.
\cite{xu2017semantic}  encodes the symbolic knowledge in Boolean logic, and derives a semantic loss to make the neural network automatically learn the symbolic knowledge. Their experiments show that the semantic loss helps to reduce the constraint violation and gives significant practical improvements in semi-supervised classification. 

Inspired by their work, we encode the constraints in \cite{chen2014encoding} to boolean logic, and add a semantic loss to the neural network.

\subsection{Argument Type Constraints}
%Describe clw's argument type constraints
%只介绍两类规则，一类是不同关系主体客体的约束，一类是相同关系主体客体的约束
\cite{chen2014encoding} derives 2 kinds of constraints (Types Constraints, Cardinality Constraints) from an existing KB to implicitly capture the expected type and cardinality requirements for a relation's arguments. 
\paragraph{Implicit Argument Types Inconsistencies:}
Generally, the argument types of the correct predictions should be consistent with each other. If the predictions among different entity tuples require the same entity to belong to different types, this is called an argument type inconsistency. Take \textless USA, New York\textgreater and \textless USA, Washington D.C.\textgreater as an example. We couldn't predict two relations for them which has different Subject types, such as $ LargestCity $ and $ LocationCity $.

\paragraph{Violations of Arguments' Uniqueness:}
Given a subject, some relation should have unique objects, vice versa. For example, given USA as the subject of the relation Capital, we can only accept one possible object, because there is great chance that a country only have one capital.

\iffalse
\begin{table}[!t]  
	\centering  
	\scriptsize  
	\begin{tabular}{ll}  
		\\[-2mm]  
		\hline  
		\hline\\[-2mm]
		\vspace{1mm}
		%\multicolumn{2}{|c|}{?}\\
		Details about Argument Type Constraints in \cite{chen2014encoding}\\
		\hline\\[-2mm]  
		\vspace{1mm}
		Given two entity tuples $(s_1, r_1, o_1), (s_2, r_2, o_2)$:\\ 
		\vspace{1mm} 
		Subj-Cons      &   \tabincell{l}{$s_1 \neq s_2 \quad when \quad r_1 \neq r_2$}\\  
		\vspace{1mm}  
		Obj-Cons       &   \tabincell{l}{$o_1 \neq o_2 \quad when \quad r_1 \neq r_2$}\\  
		\vspace{1mm}  
		Subj-Obj-Cons  &   \tabincell{l}{$s_1 \neq o_2 \vee o_1 \neq s_2 \quad when \quad r_1 \neq r_2$}\\  
		\vspace{1mm}  
		Subj-Uni       &   \tabincell{l}{$s_1 \neq s_2 \quad when \quad r_1 = r_2 \wedge o_1 = o_2$}\\  
		\vspace{1mm}  
		Obj-Uni        &   \tabincell{l}{$o_1 \neq o_2 \quad when \quad r_1 = r_2 \wedge s_1 = s_2$}\\  
		\hline  
		\hline  
	\end{tabular} 
	\caption{Argument Type Constraints}  
	\label{tab:notations}  
\end{table} 
\fi
\iffalse
Given two entity tuples $(s_1, r_1, o_1), (s_2, r_2, o_2)$: 

Subj-Cons:$s_1 \neq s_2 \quad when \quad r_1 \neq r_2$
	
Obj-Cons:$o_1 \neq o_2 \quad when \quad r_1 \neq r_2$
	
Subj-Obj-Cons:$s_1 \neq o_2 \vee o_1 \neq s_2 \quad when \quad r_1 \neq r_2$

Subj-Uni:$s_1 \neq s_2 \quad when \quad r_1 = r_2 \wedge o_1 = o_2$

Obj-Uni:$o_1 \neq o_2 \quad when \quad r_1 = r_2 \wedge s_1 = s_2$
\fi
%Subj-Cons: $r_1$ and $r_2$ can't have same subject. Obj-Cons means $r_1$ and $r_2$ can't have same object. Subj-Obj-Cons means $r_1$'s subject can't be $r_2$'s object or $r_2$'s subject can't be $r_1$'s object. Subj-Uni means if $r_1$ equals $r_2$, 


\subsection{Semantic Loss}
%Describe semantic loss, and how to encode clw's constraints into semantic loss.
\cite{xu2017semantic}  encode the symbolic knowledge in Boolean logic, and derive a semantic loss to make the neural network automatically learning the symbolic knowledge. 
%This loss function captures how close the neural network is to satisfying the constraints on its output. 

The semantic loss $L^{s}(\alpha, p)$ is a function of a sentence $\alpha$ in propositional logic, defined over variables $\bm X=\{X_1,...,X_n\}$, and a vector of probabilities $p$ for the same variables $\bm X$. Element $p_i$ denotes the predicted probability of variable $X_i$, and corresponds to a single output of the neural net. 
%For example, the semantic loss between an exactly-one constraint $\alpha$ and a neural net output vector $p$ captures how close the prediction $p$ is to having exactly one output set to true(1), and all false(0), regardless of which output is correct.
%We desire our semantic loss $L^{s}(\alpha, p)$ to be proportional to the negative log-probability of $\alpha$ being satisfied when sampling values according to $p$. More formally,
In \cite{xu2017semantic}, the semantic loss function is formed as follows,

\begin{center}
	$L^{s}(\alpha, p) = -log\sum\limits_{\bm x\models\alpha}\prod\limits_{i:\bm x\models X_i}p_i\prod\limits_{i:\bm x\models \neg X_i}(1-p_i)$
\end{center}

Here, $\bm x \models \alpha$ means that assignment $\bm x$ to variables $\bm X$ satisfies sentence $\alpha$, and $\bm x \models X_i$ means that $X_i$ is set to true in world $\bm x$. 
%Intuitively, this is the self-information of obtaining an assignment that satisfies the constraint. 

To utilize \cite{chen2014encoding}'s constraints into our neural net, we transform these constraints into boolean logic just like \cite{xu2017semantic}. For example, (Subj, Obj, Subj-Obj, rel1, rel2) = (1, 0, 0, Nationality, Birthplace) is a constraint in \cite{chen2014encoding}, limiting the argument type of relations, which means that two relation $ Nationality $ and $ Birthplace $ could have the same Subject , different Object and one relation's Subject is different with other's Object. Suppose there are 5 kinds of relations: rel1, rel2=$ Nationality $, rel3, rel4=$ Birthplace $, rel5, we encode this rule with a boolean vector (1, 0, 0, 0, 1, 0, 1, 0), the first three position indicates the (Subj, Obj, Subj-Obj) information, and the last five position indicates which two relations involved in the rule. And all the boolean form of constraints in \cite{chen2014encoding} composed of  $ \alpha $ in (1).

\subsection{Incorporating  Type Constraints During Training}

\paragraph{Base Model}
%Briefly introduce the base model (PCNN).
Our baseline model refers to \cite{lin2016neural}'s CNN with selective attention model. First, we concatenate the word embeddings and position embeddings of each word in one sentence, the position embeddings indicates how close each word is to head or tail entities. Then, we use a convolutional layer with window size 3, a max pooling layer and a non-linear layer to merge all these features and get the representation of one sentence.Then a selective attention is done over a bag of sentences to get the bag representation.

\paragraph{Training Procedure}
%How do you construct the batches?
%What is the loss function?
Here we introduce the learning and optimization details of our model. Our objective function is consists of two parts: cross-entropy loss and semantic loss.
\begin{center}
	$ J(\theta) = J_{en}(\theta) + J_{SL}(\theta)$
\end{center}

The cross-entropy loss defined as follows:
\begin{center}
	$ J_{en}(\theta)= \sum\limits_{i=1}^{s}logp(r_i|S_i, \theta)$	
\end{center}
where $ s $ indicates the number of sentence bags and $ \theta $ indicates all parameters of our model.

The semantic loss defined as follows:

For any combination of two entity pair in a batch, we use the CNN output on them to get the probability vector $ p $ in (1). Then we use (1) to calculate $L^{s}(\alpha, p)$ on all combinations of two entity pair. So we can finally get semantic loss as follows:
\begin{center}
	$ J_{SL}(\theta) = \sum\limits_{i \neq j}L^{s}(\alpha, p_{ij}) $,
\end{center}
where $0<=i<=batch-size, 0<=j<=batch-size$, $ p_{ij} $ means the probability vector calculate by $ O_i, O_j $

To solve the optimization problem, we adopt Adam \cite{kingma2014adam} to minimize the objective function. For learning, we iterate by randomly selecting a mini-batch from the training set until converge.
\paragraph{Simplified Semantic Loss}

%Describe the simplified version of the semantic loss.
In our experiments, we find that the way \cite{xu2017semantic} calculating semantic loss is time-consuming, so we simplify the semantic loss calculation without losing much performance, which greatly reduces the time overhead.

In (1), we need calculate semantic loss for every $ \bm x (\bm x \models \alpha)$, but we find that for each entity pair combination, there exists $ \bm x $ that is more important than others. So we use the gold information of entity pairs to find the most important positive rule, and random sample some rules as a supplement. This significantly reduces the computational complexity.

